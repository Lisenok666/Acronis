# Acronis

Решал первую задачу https://docs.google.com/document/d/1iyXWeGTu30L7ex02c62JDQhe3ayUzclm5K5bGDzGpdQ/edit#heading=h.d77tb6uoaktk

Ваша задача:
1.       Построить одну или несколько моделей, предсказывающих следующее значение целевой метрики latency_ms_sum в зависимости от предыдущих значений всех остальных метрик.
2.       Построить на одном графике реальное значение метрики latency_ms_sum и предсказанное.
3.       Построить график ошибки предсказаний в зависимости от календарного времени.
4.       Найти все интервалы времени аномального поведения сервиса и отобразить их на графике метрики latency_ms_sum в зависимости от календарного времени.


Впринципе, в ноутбуке примерно описан ход решения, но для удобство кратко повторю его здесь, тем более во многие пункты можно написать более развернуто.

Шаг 0:

Изучить данные. На этом шаге мной были найдены около 300 неполных строк в датасете и так как на около 8 тысяч данных 300, это очень мало, эти данные были мной просто удалены из датасета.(Хотя возможно стоило их обработать, установив в них значение -1, которое из описание наших данных не может встречаться ни в одной из строк).


Пункт 1 и 2:

Чтобы сильно не увеличивать объём Readme принцип работы алгоритмов я не буду их описывать, если вы захотите я смогу рассказать Вам принцип их работы на собеседовании.

Чем обуслевлен выбор моделей?

Линейная регрессия и решающие дерево были выбраны, как хорошо интерпретируемые алгоритмы, работу которых могут понять люди несвязанные с ML.

Учитывая, что результаты линейной регрессиии мне не понравились(огромная ошибка), я не стал "играться с параметрами" и бороться с переобучением, которого не было.

L1, L2 регуляризации, были применены  скорее для очищения совести и чтобы показать, чтоя знаю о их существовании ;)

В решающем дереве я искал лучшую глубину, тут уже приходиться бороться с переобучением, для этого я использовал крос валидацию.

XGBBoost я использовал для того чтобы посмотреть как будет вести себя более сложная модель.  В нём я варьировал глубину деревьев и их колличество.

Пункт 3:

здесь всё довольно просто. Берём лучшую модель(у нас это решающее дерево), вычисляем ошибку и строим график.

Пункт 4:

Я не до конца уверен, что сделал именно то что от меня требуется. Вообще поиск аномалий довольно сложный.

Я построил график методом TSNE, на котором видно что наши данные представляют собой 3 класса. И эти классы видны на графике time_stamp от целевой переменной, но kmeans разбил данные на классы не совсем та как предпологалось из графике time_stamp от целевой переменной.

При этом сложно назвать какой-то из классов аномальным, т.к. ни один из них не совподает с пиком ошибок на графике из 3 пункта.


Скорее всего вывод в том, что надо было использовать какой-то другой метод(предположу одноклассовый SVM), но к сожалению я получил не аномалии кластеризацию данных.


Надеюсь Вы дочитали до этого момента и позовёте меня на собеседование:)

С уважением, Лескевич Даниил.

